{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"C:/Users/DeepScan/Downloads/Images/test_data/\"\n",
    "real_dest_dir = base_dir + 'train_real_faces'\n",
    "fake_dest_dir = base_dir + 'train_fake_faces'\n",
    "\n",
    "real_src_dir = \"C:/Users/DeepScan/Downloads/Images/working_data_with_48_real_fps/train_real_faces\"\n",
    "fake_src_dir = \"C:/Users/DeepScan/Downloads/Images/working_data_with_48_real_fps/train_fake_faces\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_files(src, dest):\n",
    "    if not os.path.exists(dest):\n",
    "        os.makedirs(dest)\n",
    "\n",
    "    src_files = os.listdir(src)\n",
    "    for i in range(15):\n",
    "        random.shuffle(src_files)\n",
    "\n",
    "    for file in src_files[:5000]:\n",
    "        shutil.copy2(os.path.join(src, file), dest)\n",
    "\n",
    "move_files(real_src_dir, real_dest_dir)\n",
    "move_files(fake_src_dir, fake_dest_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Models Evaluation\n",
    "\n",
    "This evaluation is being performed using the sota weights. sota here refers to the best model trained by us on smaller subset like 400 real & fake videos & now wanna test out on large quantity of unseen test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Processing\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "# Face extraction, cropping & display\n",
    "import cv2\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Model Training\n",
    "from __future__ import print_function\n",
    "from itertools import chain\n",
    "import csv\n",
    "import random\n",
    "import os.path as osp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision.transforms import ToPILImage\n",
    "from PIL import Image\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "import torchvision.transforms as transforms\n",
    "import timm\n",
    "from tabulate import tabulate\n",
    "\n",
    "from sklearn.metrics import log_loss, f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import dlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"C:/Users/DeepScan/Downloads/Images/test_data/\"\n",
    "train_real_faces = base_dir + 'train_real_faces'\n",
    "train_fake_faces = base_dir + 'train_fake_faces'\n",
    "\n",
    "train_real_data = [os.path.join(train_real_faces, f) for f in os.listdir(train_real_faces)]\n",
    "train_fake_data = [os.path.join(train_fake_faces, f) for f in os.listdir(train_fake_faces)]\n",
    "\n",
    "test_images = train_fake_data + train_real_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(15):\n",
    "    np.random.shuffle(test_images)\n",
    "\n",
    "frame = pd.DataFrame(test_images, columns=['path'])\n",
    "# Add the new 'label' column\n",
    "frame['label'] = frame['path'].apply(lambda x: 0 if 'real' in x else 1)\n",
    "frame.to_csv(f'{base_dir}/celebdf_v2_test_images.csv', index=False, sep=',', header=True, encoding='utf-8')\n",
    "\n",
    "celebdf_test_csv = pd.read_csv(f\"{base_dir}/celebdf_v2_test_images.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++++Evaluating swin_base_patch4_window7_224 trained on CelebDF-v2+++++++++++++\n",
      "+++++++++++++Loaded 10_epochs.pth weights!+++++++++++++\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 313/313 [00:29<00:00, 10.44batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+----------+------------+\n",
      "|   Logloss |   AUC Score |       F1 |   Accuracy |\n",
      "+===========+=============+==========+============+\n",
      "|   3.08927 |    0.248183 | 0.303041 |     0.2116 |\n",
      "+-----------+-------------+----------+------------+\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "+++++++++++++Evaluating swin_base_patch4_window7_224 trained on CelebDF-v2+++++++++++++\n",
      "+++++++++++++Loaded 12_epochs.pth weights!+++++++++++++\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 313/313 [00:23<00:00, 13.42batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+----------+------------+\n",
      "|   Logloss |   AUC Score |       F1 |   Accuracy |\n",
      "+===========+=============+==========+============+\n",
      "|   3.61621 |    0.248503 | 0.314326 |     0.2208 |\n",
      "+-----------+-------------+----------+------------+\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "+++++++++++++Evaluating swin_base_patch4_window7_224 trained on CelebDF-v2+++++++++++++\n",
      "+++++++++++++Loaded 15_epochs.pth weights!+++++++++++++\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 313/313 [00:23<00:00, 13.45batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+----------+------------+\n",
      "|   Logloss |   AUC Score |       F1 |   Accuracy |\n",
      "+===========+=============+==========+============+\n",
      "|    3.8173 |    0.312209 | 0.238395 |     0.1764 |\n",
      "+-----------+-------------+----------+------------+\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "+++++++++++++Evaluating swin_base_patch4_window7_224 trained on CelebDF-v2+++++++++++++\n",
      "+++++++++++++Loaded 17_epochs.pth weights!+++++++++++++\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 313/313 [00:29<00:00, 10.76batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+----------+------------+\n",
      "|   Logloss |   AUC Score |       F1 |   Accuracy |\n",
      "+===========+=============+==========+============+\n",
      "|   4.42586 |    0.259743 | 0.265164 |     0.1847 |\n",
      "+-----------+-------------+----------+------------+\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "+++++++++++++Evaluating swin_base_patch4_window7_224 trained on CelebDF-v2+++++++++++++\n",
      "+++++++++++++Loaded 20_epochs.pth weights!+++++++++++++\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 313/313 [00:28<00:00, 11.10batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+----------+------------+\n",
      "|   Logloss |   AUC Score |       F1 |   Accuracy |\n",
      "+===========+=============+==========+============+\n",
      "|   3.82732 |    0.143728 | 0.565076 |     0.3975 |\n",
      "+-----------+-------------+----------+------------+\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "+++++++++++++Evaluating swin_base_patch4_window7_224 trained on CelebDF-v2+++++++++++++\n",
      "+++++++++++++Loaded 3_epochs.pth weights!+++++++++++++\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 313/313 [00:28<00:00, 11.06batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+----------+------------+\n",
      "|   Logloss |   AUC Score |       F1 |   Accuracy |\n",
      "+===========+=============+==========+============+\n",
      "|   1.78937 |    0.229448 | 0.374643 |     0.2552 |\n",
      "+-----------+-------------+----------+------------+\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "+++++++++++++Evaluating swin_base_patch4_window7_224 trained on CelebDF-v2+++++++++++++\n",
      "+++++++++++++Loaded 7_epochs.pth weights!+++++++++++++\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 313/313 [00:28<00:00, 10.97batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+----------+------------+\n",
      "|   Logloss |   AUC Score |       F1 |   Accuracy |\n",
      "+===========+=============+==========+============+\n",
      "|   2.52889 |    0.271209 | 0.295834 |     0.2107 |\n",
      "+-----------+-------------+----------+------------+\n",
      "====================================================================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PATH = \"Z:/Deepscan-Repository/evaluation/sota_weights\"\n",
    "model_name = \"swin_base_patch4_window7_224\"\n",
    "\n",
    "for file in os.listdir(PATH):\n",
    "    if file.endswith(\".pth\"):\n",
    "        model_path = os.path.join(PATH, file)\n",
    "        model = timm.create_model('swin_base_patch4_window7_224', pretrained=True, num_classes=2).to(device)\n",
    "        model.load_state_dict(torch.load(model_path, map_location=torch.device(device)))\n",
    "\n",
    "        print(f'+++++++++++++Evaluating {model_name} trained on CelebDF-v2+++++++++++++')\n",
    "        print(f\"+++++++++++++Loaded {file} weights!+++++++++++++\")\n",
    "\n",
    "        # Create the save path\n",
    "        save_dir = os.path.join(f\"Z:/Deepscan-Repository/evaluation/swin_no_aug_testsplit_randomframes/400_400_subset_sota/{file}\")\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "\n",
    "        save_path = os.path.join(save_dir, f\"{os.path.splitext(file)[0]}_pth_result.csv\")\n",
    "\n",
    "        torch.manual_seed(42)\n",
    "        Evaluate(model, celebdf_test_csv, save_path)\n",
    "\n",
    "        print('====================================================================================================\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def get_scores(predictions):\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "    predicted_probs = []\n",
    "\n",
    "    for key, value in predictions.items():\n",
    "        predicted_probs.append(value[0])\n",
    "        predicted_labels.append(value[1])\n",
    "        true_labels.append(value[2])\n",
    "\n",
    "    logloss = log_loss(true_labels, predicted_probs)\n",
    "    auc = roc_auc_score(true_labels, predicted_probs)\n",
    "    f1 = f1_score(true_labels, predicted_labels)\n",
    "    acc = accuracy_score(true_labels, predicted_labels)\n",
    "        \n",
    "    print(tabulate([[logloss, auc, f1, acc]], headers=['Logloss', 'AUC Score', 'F1', 'Accuracy'], tablefmt=\"grid\"))\n",
    "    return logloss, auc, f1, acc\n",
    "\n",
    "def Evaluate(model, faces_path_dict, save_path, batch_size=32):\n",
    "        \n",
    "    labels_map = ['real', 'fake']\n",
    "    predictions = {}\n",
    "    faces = []\n",
    "\n",
    "    # Preprocess the faces\n",
    "    for img in faces_path_dict['path']:\n",
    "        if img.endswith('.jpg'):\n",
    "            face = cv2.imread(img)\n",
    "            faces.append(face)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "    ])\n",
    "\n",
    "    # Create batches of preprocessed face tensors\n",
    "    face_tensors = [transform(Image.fromarray(face)).unsqueeze(0).to(device) for face in faces]\n",
    "    batches = [face_tensors[i:i+batch_size] for i in range(0, len(face_tensors), batch_size)]\n",
    "\n",
    "    # Run the model on the batches\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(batches, desc=\"Processing images\", unit=\"batch\"):\n",
    "            outputs = model(torch.cat(batch, dim=0))\n",
    "            batch_probability_fake = torch.softmax(outputs, 1)[:, 1].tolist()\n",
    "            batch_probability_real = torch.softmax(outputs, 1)[:, 0].tolist()\n",
    "\n",
    "            for i, img in enumerate(faces_path_dict['path'][len(predictions):len(predictions)+len(batch)]):\n",
    "                original_label = 0 if 'real' in img else 1\n",
    "                if labels_map[torch.argmax(outputs[i]).item()] == 'fake':\n",
    "                    predictions[img] = [batch_probability_fake[i], 1, original_label]\n",
    "                else:\n",
    "                    predictions[img] = [batch_probability_real[i], 0, original_label]\n",
    "\n",
    "                # Print the tabulated data for each iteration\n",
    "                # print(tabulate([[img, predictions[img][0], predictions[img][1], predictions[img][2]]], tablefmt='simple_grid'))\n",
    "\n",
    "    with open(save_path, \"w\", newline=\"\") as csvfile:\n",
    "        fieldnames = [\"ImagePath\", \"ProbabilityScore\", \"PredictedLabel\", \"OriginalLabel\"]\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames, lineterminator=\"\\n\")\n",
    "        writer.writeheader()\n",
    "        for img, prediction in predictions.items():\n",
    "            writer.writerow(\n",
    "                {\n",
    "                    \"ImagePath\": img,\n",
    "                    \"ProbabilityScore\": prediction[0],\n",
    "                    \"PredictedLabel\": prediction[1],\n",
    "                    \"OriginalLabel\": prediction[2],\n",
    "                }\n",
    "            )\n",
    "\n",
    "    logloss, auc, f1, acc = get_scores(predictions)\n",
    "    with open(save_path, \"a\", newline=\"\") as csvfile:\n",
    "        fieldnames = [\"LogLoss\", \"AUC\", \"F1-Score\", \"Accuracy\"]\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames, lineterminator=\"\\n\")\n",
    "        writer.writeheader()\n",
    "        writer.writerow({\"LogLoss\": logloss, \"AUC\": auc, \"F1-Score\": f1, \"Accuracy\": acc})\n",
    "\n",
    "    torch.cuda.empty_cache()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepfake_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
